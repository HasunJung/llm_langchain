{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOrMDHJ5zqvCuZCtPc9w6/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HasunJung/llm_langchain/blob/main/06_chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INSTALL"
      ],
      "metadata": {
        "id": "lhcMwKgw_Uif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ìµœì´ˆ ì‹¤í–‰ì´ë¼ë©´\n",
        "!pip install -q langchain langchain-google-genai\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# ChatGoogleGenerativeAI ì–¸ì–´ ëª¨ë¸ì„ \"gemini-pro\" ëª¨ë¸ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)"
      ],
      "metadata": {
        "id": "MyyXlAZ3_YCu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain"
      ],
      "metadata": {
        "id": "i92ITd7ACghZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChainsëŠ” ì¼ë ¨ì˜ ì²˜ë¦¬ë¥¼ í•˜ë‚˜ì˜ ë¬¶ìŒìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.\n",
        "- ì—¬ëŸ¬ ëª¨ë“ˆì˜ ì¡°í•©ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ : ë­ì²´ì¸ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ë•ŒëŠ” í•˜ë‚˜ì˜ ëª¨ë“ˆë§Œìœ¼ë¡œ ì›í•˜ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ê¸° ì–´ë µë‹¤.\n",
        "- íŠ¹ì • ìš©ë„ì— íŠ¹í™”ëœ ì²´ì¸ : ì–¸ì–´ ëª¨ë¸ì˜ í˜¸ì¶œë§Œìœ¼ë¡œëŠ” ëŒ€ì‘í•˜ê¸° ì–´ë ¤ìš´ ê¸°ëŠ¥ì´ë‚˜ ë³µì¡í•œ ì²˜ë¦¬ë¥¼ ë­ì²´ì¸ ì¸¡ì—ì„œ ë¯¸ë¦¬ ë‚´ì¥í•´ íŠ¹ì • ìš©ë„ì— íŠ¹í™”ëœ Chainsë„ ì¡´ì¬í•œë‹¤.\n",
        "- ì²´ì¸ ìì²´ë¥¼ ì •ë¦¬í•œë‹¤ : Chainsì€ ê¸°ëŠ¥ ë©ì–´ë¦¬ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ì´ ë©ì–´ë¦¬ë¥¼ ì—¬ëŸ¬ê°œ ì¤€ë¹„í•´ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ê±°ë‚˜ í•„ìš”ì— ë”°ë¼ í˜¸ì¶œ í•  ìˆ˜ ìˆë„ë¡ Chains ìì²´ë¥¼ ë¬¶ì„ ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "\n",
        "ë‹¤ë§Œ ChainsëŠ” ì•”ë¬µì ìœ¼ë¡œ ì²˜ë¦¬í•´ ë¸”ë™ë°•ìŠ¤ê°€ ë˜ê¸° ì‰¬ìš°ë¯€ë¡œ, ê° ëª¨ë“ˆì´ ì–´ë–¤ ì²˜ë¦¬ë¥¼ í•˜ëŠ”ì§€ ì œëŒ€ë¡œ ì´í•´í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "1N5aLZG9CirZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConversationChain"
      ],
      "metadata": {
        "id": "3aDXEEU9_06C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë©”ëª¨ë¦¬ ëª¨ë“ˆê³¼ ë‹¤ë¥¸ ëª¨ë“ˆì„ ì‰½ê²Œ ì¡°í•©í•  ìˆ˜ ìˆëŠ” ë‚´ì¥ ëª¨ë“ˆì…ë‹ˆë‹¤.\n",
        "\n",
        "ConversationChain, ConversationBufferMemory ëª¨ë“ˆì€ ëŒ€í™” ê´€ë¦¬ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬ì— í•„ìš”í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "ConversationChain í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ ëŒ€í™” ê´€ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ë•Œ, llmì€ ì €ìˆ˜ì¤€ ì–¸ì–´ ëª¨ë¸ì„, verboseëŠ” ìƒì„¸í•œ ë¡œê¹… ì—¬ë¶€ë¥¼ (ì—¬ê¸°ì„œëŠ” ë¹„í™œì„±í™”), ê·¸ë¦¬ê³  memoryëŠ” ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•  ë©”ëª¨ë¦¬ ë²„í¼ë¥¼ ê°ê° ì§€ì •í•©ë‹ˆë‹¤.\n"
      ],
      "metadata": {
        "id": "iMfagwIJV3Cc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bdKrFexT6Sgs"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# ConversationChain ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "# llm: ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "# verbose: ìƒì„¸í•œ ë¡œê¹…ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.\n",
        "# memory: ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ëŠ” ë©”ëª¨ë¦¬ ë²„í¼ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True, # trueë¡œ ì„¤ì •ì‹œ Chainsë‚´ë¶€ì—ì„œ ì–´ë–¤ ì²˜ë¦¬ê°€ ì´ë¤„ì§€ëŠ”ì§€ ì¶”ì  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    memory=ConversationBufferMemory(memory_key=\"history\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "conversation.predict í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•œ ëª¨ë¸ì˜ ë°˜ì‘ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "sxPQoUpgAPG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.invoke({\"input\": \"ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜.\"})"
      ],
      "metadata": {
        "id": "yWg4l8e_6azW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe4187f7-b18c-4c00-ac78-af47f8089c80"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜.',\n",
              " 'history': '',\n",
              " 'response': 'ì–‘ìì—­í•™ì€ ë¬¼ì§ˆê³¼ ì—ë„ˆì§€ì˜ ë§¤ìš° ì‘ì€ ê·œëª¨ì—ì„œì˜ ê±°ë™ì„ ì„¤ëª…í•˜ëŠ” ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. ì´ ì´ë¡ ì€ 20ì„¸ê¸° ì´ˆì— ê°œë°œë˜ì—ˆìœ¼ë©°, ê³ ì „ ë¬¼ë¦¬í•™ìœ¼ë¡œëŠ” ì„¤ëª…í•  ìˆ˜ ì—†ëŠ” í˜„ìƒì„ ì„¤ëª…í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì˜ í•µì‹¬ ê°œë… ì¤‘ í•˜ë‚˜ëŠ” ì´ì¤‘ì„±ì…ë‹ˆë‹¤. ì´ì¤‘ì„±ì€ ì…ìê°€ íŒŒë™ê³¼ ì…ìì˜ ì„±ì§ˆì„ ë™ì‹œì— ê°€ì§ˆ ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë¹›ì€ íŒŒë™ìœ¼ë¡œë„ ì…ì(ê´‘ì)ë¡œë„ í–‰ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në˜ ë‹¤ë¥¸ í•µì‹¬ ê°œë…ì€ ë¶ˆí™•ì •ì„± ì›ë¦¬ì…ë‹ˆë‹¤. ë¶ˆí™•ì •ì„± ì›ë¦¬ëŠ” ì…ìì˜ ìœ„ì¹˜ì™€ ìš´ë™ëŸ‰ì„ ë™ì‹œì— ì •í™•í•˜ê²Œ ì•Œ ìˆ˜ ì—†ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ì…ìê°€ íŒŒë™ê³¼ ê°™ì€ ì„±ì§ˆì„ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì€ ë ˆì´ì €, íŠ¸ëœì§€ìŠ¤í„°, í•µë¬´ê¸°ì™€ ê°™ì€ ë§ì€ í˜„ëŒ€ ê¸°ìˆ ì˜ ê¸°ë°˜ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ ì–‘ì ì»´í“¨íŒ…ê³¼ ê°™ì€ ìƒˆë¡œìš´ ê¸°ìˆ  ë¶„ì•¼ì˜ ê°œë°œì—ë„ ì˜ê°ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì€ ë§¤ìš° ë³µì¡í•œ ì´ë¡ ì´ì§€ë§Œ, ë¬¼ì§ˆê³¼ ì—ë„ˆì§€ì˜ ê¸°ë³¸ì ì¸ ì„±ì§ˆì„ ì´í•´í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.memory.load_memory_variables({})[\"history\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "92SAYjhCWTcH",
        "outputId": "fb81b6f8-0af1-47fc-9055-269dfedce434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜.\\nAI: ì–‘ìì—­í•™ì€ ì›ìì™€ ì›ìë³´ë‹¤ ì‘ì€ ì…ìì˜ ê±°ë™ì„ ì„¤ëª…í•˜ëŠ” ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. 20ì„¸ê¸° ì´ˆì— ê°œë°œë˜ì—ˆìœ¼ë©°, ê³ ì „ ë¬¼ë¦¬í•™ì˜ ë²•ì¹™ìœ¼ë¡œëŠ” ì„¤ëª…í•  ìˆ˜ ì—†ëŠ” ê´€ì°° ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ê¸° ìœ„í•´ ê³ ì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì˜ ì£¼ìš” ê°œë… ì¤‘ í•˜ë‚˜ëŠ” ì´ì¤‘ì„±ì…ë‹ˆë‹¤. ì´ì¤‘ì„±ì€ ì…ìê°€ ì…ìì™€ íŒŒë™ì˜ íŠ¹ì„±ì„ ëª¨ë‘ ê°€ì§ˆ ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ì…ìê°€ ê°„ì„­í•˜ê³  íšŒì ˆë  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•˜ë©°, ì´ëŠ” íŒŒë™ì´ í•˜ëŠ” ì¼ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì…ìëŠ” ë˜í•œ ìš´ë™ëŸ‰ê³¼ ì—ë„ˆì§€ì™€ ê°™ì€ ì…ì íŠ¹ì„±ë„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì˜ ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ ê°œë…ì€ ë¶ˆí™•ì •ì„± ì›ë¦¬ì…ë‹ˆë‹¤. ë¶ˆí™•ì •ì„± ì›ë¦¬ëŠ” ì–´ë–¤ ì…ìì˜ ìœ„ì¹˜ì™€ ìš´ë™ëŸ‰ì„ ë™ì‹œì— ì •í™•í•˜ê²Œ ì•Œ ìˆ˜ ì—†ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ì…ìì˜ ìœ„ì¹˜ë¥¼ ë” ì •í™•í•˜ê²Œ ì•Œë©´ ìš´ë™ëŸ‰ì— ëŒ€í•œ ì •ë³´ê°€ ì¤„ì–´ë“¤ê³ , ë°˜ëŒ€ì˜ ê²½ìš°ë„ ë§ˆì°¬ê°€ì§€ì…ë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì€ í˜„ëŒ€ ë¬¼ë¦¬í•™ì—ì„œ ê°€ì¥ ì„±ê³µì ì¸ ì´ë¡  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ë ˆì´ì €, íŠ¸ëœì§€ìŠ¤í„°, í•µë¬´ê¸° ë“±ì˜ ë§ì€ í˜„ëŒ€ ê¸°ìˆ ì˜ ê¸°ë°˜ì„ í˜•ì„±í–ˆìŠµë‹ˆë‹¤. ë˜í•œ ì–‘ìì—­í•™ì€ ìš°ì£¼ì˜ ê·¼ë³¸ì ì¸ ì„±ì§ˆì„ ì´í•´í•˜ëŠ” ë°ì—ë„ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.memory.save_context(inputs={\"human\": \"hi\"}, outputs={\"ai\": \"ì•ˆë…•\"})"
      ],
      "metadata": {
        "id": "bLz0nz2sWW-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.memory.load_memory_variables({})[\"history\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "JCJugRTAWZZ_",
        "outputId": "043fcfbc-788b-4834-be8c-4e7b66dd6519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜.\\nAI: ì–‘ìì—­í•™ì€ ì›ìì™€ ì›ìë³´ë‹¤ ì‘ì€ ì…ìì˜ ê±°ë™ì„ ì„¤ëª…í•˜ëŠ” ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. 20ì„¸ê¸° ì´ˆì— ê°œë°œë˜ì—ˆìœ¼ë©°, ê³ ì „ ë¬¼ë¦¬í•™ì˜ ë²•ì¹™ìœ¼ë¡œëŠ” ì„¤ëª…í•  ìˆ˜ ì—†ëŠ” ê´€ì°° ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ê¸° ìœ„í•´ ê³ ì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì˜ ì£¼ìš” ê°œë… ì¤‘ í•˜ë‚˜ëŠ” ì´ì¤‘ì„±ì…ë‹ˆë‹¤. ì´ì¤‘ì„±ì€ ì…ìê°€ ì…ìì™€ íŒŒë™ì˜ íŠ¹ì„±ì„ ëª¨ë‘ ê°€ì§ˆ ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ì…ìê°€ ê°„ì„­í•˜ê³  íšŒì ˆë  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•˜ë©°, ì´ëŠ” íŒŒë™ì´ í•˜ëŠ” ì¼ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì…ìëŠ” ë˜í•œ ìš´ë™ëŸ‰ê³¼ ì—ë„ˆì§€ì™€ ê°™ì€ ì…ì íŠ¹ì„±ë„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì˜ ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ ê°œë…ì€ ë¶ˆí™•ì •ì„± ì›ë¦¬ì…ë‹ˆë‹¤. ë¶ˆí™•ì •ì„± ì›ë¦¬ëŠ” ì–´ë–¤ ì…ìì˜ ìœ„ì¹˜ì™€ ìš´ë™ëŸ‰ì„ ë™ì‹œì— ì •í™•í•˜ê²Œ ì•Œ ìˆ˜ ì—†ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ì…ìì˜ ìœ„ì¹˜ë¥¼ ë” ì •í™•í•˜ê²Œ ì•Œë©´ ìš´ë™ëŸ‰ì— ëŒ€í•œ ì •ë³´ê°€ ì¤„ì–´ë“¤ê³ , ë°˜ëŒ€ì˜ ê²½ìš°ë„ ë§ˆì°¬ê°€ì§€ì…ë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì€ í˜„ëŒ€ ë¬¼ë¦¬í•™ì—ì„œ ê°€ì¥ ì„±ê³µì ì¸ ì´ë¡  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ë ˆì´ì €, íŠ¸ëœì§€ìŠ¤í„°, í•µë¬´ê¸° ë“±ì˜ ë§ì€ í˜„ëŒ€ ê¸°ìˆ ì˜ ê¸°ë°˜ì„ í˜•ì„±í–ˆìŠµë‹ˆë‹¤. ë˜í•œ ì–‘ìì—­í•™ì€ ìš°ì£¼ì˜ ê·¼ë³¸ì ì¸ ì„±ì§ˆì„ ì´í•´í•˜ëŠ” ë°ì—ë„ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.\\nHuman: hi\\nAI: ì•ˆë…•'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(conversation.invoke({\"input\": \"ë¶ˆë ›í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì¤˜. emoji ì¶”ê°€í•´ì¤˜.\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "31avUHcYWh8T",
        "outputId": "88eea114-697a-4f94-a43f-ed55270a3743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'input': 'ë¶ˆë ›í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì¤˜. emoji ì¶”ê°€í•´ì¤˜.',\n",
              " 'history': 'Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\\nAI: ì–‘ìì—­í•™ì€ ë¬¼ì§ˆê³¼ ì—ë„ˆì§€ì˜ ê°€ì¥ ì‘ì€ êµ¬ì„± ìš”ì†Œì¸ ì›ìì™€ ì•„ì›ì ì…ìì˜ í–‰ë™ì„ ì„¤ëª…í•˜ëŠ” ë¬¼ë¦¬í•™ ë¶„ì•¼ì…ë‹ˆë‹¤. ì´ ì´ë¡ ì€ ë¹›ì´ ì…ì(ê´‘ì)ì™€ íŒŒë™ì˜ ì„±ì§ˆì„ ë™ì‹œì— ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì´ì¤‘ì„±ê³¼ ê°™ì€ ì§ê´€ì— ì–´ê¸‹ë‚˜ëŠ” í˜„ìƒì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\\n\\ní•µì‹¬ ê°œë… ì¤‘ ì¼ë¶€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n* **íŒŒë™-ì…ì ì´ì¤‘ì„±:** ì…ìëŠ” íŒŒë™ê³¼ ê°™ì€ ì„±ì§ˆì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n* **ë¶ˆí™•ì •ì„± ì›ë¦¬:** ì…ìì˜ ìœ„ì¹˜ì™€ ìš´ë™ëŸ‰ì„ ë™ì‹œì— ì •í™•í•˜ê²Œ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\\n* **ì¤‘ì²©:** ì…ìëŠ” ì—¬ëŸ¬ ìƒíƒœì— ë™ì‹œì— ì¡´ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n* **ì–‘ì ì–½í˜:** ì„œë¡œ ë©€ë¦¬ ë–¨ì–´ì§„ ë‘ ì…ìê°€ ì—°ê²°ë˜ì–´ í•˜ë‚˜ì˜ ì…ìì— ëŒ€í•œ ì¸¡ì •ì´ ë‹¤ë¥¸ ì…ìì˜ ìƒíƒœì— ì¦‰ì‹œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.\\n\\nì–‘ìì—­í•™ì€ ë ˆì´ì €, íŠ¸ëœì§€ìŠ¤í„°, MRI ê¸°ê³„ì™€ ê°™ì€ í˜„ëŒ€ ê¸°ìˆ ì˜ ê¸°ë°˜ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ ìš°ì£¼ ì´ˆê¸°ì˜ ê±°ë™ê³¼ ë¸”ë™í™€ì˜ ì„±ì§ˆì„ ì´í•´í•˜ëŠ” ë°ì—ë„ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\\nHuman: ì´ì „ì˜ ë‚´ìš©ì„ ë¶ˆë ›í¬ì¸íŠ¸ë¡œ ìš”ì•½í•´ì¤˜. emoji ì¶”ê°€í•´ì¤˜.\\nAI: * **íŒŒë™-ì…ì ì´ì¤‘ì„± ğŸŒŠ ç²’å­:** ì…ìëŠ” íŒŒë™ì²˜ëŸ¼ í–‰ë™í•  ìˆ˜ ìˆì–´ìš”.\\n* **ë¶ˆí™•ì •ì„± ì›ë¦¬ âš–ï¸:** ì…ìì˜ ìœ„ì¹˜ì™€ ìš´ë™ëŸ‰ì„ ë™ì‹œì— ì •í™•íˆ ì•Œ ìˆ˜ ì—†ì–´ìš”.\\n* **ì¤‘ì²© ğŸ‘¥:** ì…ìëŠ” ì—¬ëŸ¬ ìƒíƒœì— ë™ì‹œì— ì¡´ì¬í•  ìˆ˜ ìˆì–´ìš”.\\n* **ì–‘ì ì–½í˜ ğŸ”—:** ë©€ë¦¬ ë–¨ì–´ì§„ ì…ìë“¤ì´ ì„œë¡œ ì—°ê²°ë˜ì–´ ìˆì–´ìš”. í•œ ì…ìë¥¼ ì¸¡ì •í•˜ë©´ ë‹¤ë¥¸ ì…ìì˜ ìƒíƒœì— ì˜í–¥ì„ ë¯¸ì³ìš”.\\n* **í˜„ëŒ€ ê¸°ìˆ ì˜ ê¸°ë°˜ ğŸ’¡ğŸ’»:** ë ˆì´ì €, íŠ¸ëœì§€ìŠ¤í„°, MRI ê¸°ê³„ ë“±ì˜ ê¸°ë°˜ì´ì—ìš”.\\n* **ìš°ì£¼ì™€ ë¸”ë™í™€ ì´í•´ì— ê¸°ì—¬ ğŸŒŒğŸ•³ï¸:** ìš°ì£¼ ì´ˆê¸°ì™€ ë¸”ë™í™€ì˜ ì„±ì§ˆì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë˜ìš”.',\n",
              " 'response': '* **íŒŒë™-ì…ì ì´ì¤‘ì„± ğŸŒŠ ç²’å­:** ì…ìëŠ” íŒŒë™ì²˜ëŸ¼ í–‰ë™í•  ìˆ˜ ìˆì–´ìš”.\\n* **ë¶ˆí™•ì •ì„± ì›ë¦¬ âš–ï¸:** ì…ìì˜ ìœ„ì¹˜ì™€ ìš´ë™ëŸ‰ì„ ë™ì‹œì— ì •í™•íˆ ì•Œ ìˆ˜ ì—†ì–´ìš”.\\n* **ì¤‘ì²© ğŸ‘¥:** ì…ìëŠ” ì—¬ëŸ¬ ìƒíƒœì— ë™ì‹œì— ì¡´ì¬í•  ìˆ˜ ìˆì–´ìš”.\\n* **ì–‘ì ì–½í˜ ğŸ”—:** ë©€ë¦¬ ë–¨ì–´ì§„ ì…ìë“¤ì´ ì„œë¡œ ì—°ê²°ë˜ì–´ ìˆì–´ìš”. í•œ ì…ìë¥¼ ì¸¡ì •í•˜ë©´ ë‹¤ë¥¸ ì…ìì˜ ìƒíƒœì— ì˜í–¥ì„ ë¯¸ì³ìš”.\\n* **í˜„ëŒ€ ê¸°ìˆ ì˜ ê¸°ë°˜ ğŸ’¡ğŸ’»:** ë ˆì´ì €, íŠ¸ëœì§€ìŠ¤í„°, MRI ê¸°ê³„ ë“±ì˜ ê¸°ë°˜ì´ì—ìš”.\\n* **ìš°ì£¼ì™€ ë¸”ë™í™€ ì´í•´ì— ê¸°ì—¬ ğŸŒŒğŸ•³ï¸:** ìš°ì£¼ ì´ˆê¸°ì™€ ë¸”ë™í™€ì˜ ì„±ì§ˆì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë˜ìš”.'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ìœ„ ë‚´ìš©ì„ ì‹¤ì‹œê°„ ì¶œë ¥í•˜ë„ë¡ ì²˜ë¦¬í•œë‹¤ë©´"
      ],
      "metadata": {
        "id": "cCYNUFaKWvM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.callbacks.base import BaseCallbackHandler\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "class StreamingHandler(BaseCallbackHandler):\n",
        "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
        "        print(f\"{token}\", end=\"\", flush=True)\n",
        "\n",
        "\n",
        "# ìŠ¤íŠ¸ë¦¬ë°ì„ í™œì„±í™”í•˜ê¸° ìœ„í•´, ChatModel ìƒì„±ìì— `streaming=True`ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
        "# ì¶”ê°€ì ìœ¼ë¡œ, ì‚¬ìš©ì ì •ì˜ í•¸ë“¤ëŸ¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
        "stream_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\", streaming=True, callbacks=[StreamingHandler()]\n",
        ")\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=stream_llm,\n",
        "    verbose=False,\n",
        "    memory=ConversationBufferMemory(),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "6gQycypOWy1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conversation.predict ë©”ì†Œë“œëŠ” ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "# ì´ ì˜ˆì‹œì—ì„œëŠ” 'ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜'ë¼ëŠ” ë¬¸ìì—´ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ë©°, í•´ë‹¹ ì…ë ¥ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ output ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
        "#ì´ ê³¼ì •ì€ AI ê¸°ë°˜ ëŒ€í™” ì‹œìŠ¤í…œì—ì„œ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ì„¤ëª…ì„ ìš”ì²­í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
        "output = conversation.predict(input=\"ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\")"
      ],
      "metadata": {
        "id": "0gD7QTEDXWkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = conversation.predict(\n",
        "    input=\"ì´ì „ì˜ ë‚´ìš©ì„ ë¶ˆë ›í¬ì¸íŠ¸ë¡œ ìš”ì•½í•´ì¤˜. emoji ì¶”ê°€í•´ì¤˜.\"\n",
        ")"
      ],
      "metadata": {
        "id": "vizpyQn_XXP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì›¹ë¬¸ì„œ ì²´ì¸ í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "osrAL3pWX6RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchainhub\n",
        "\n",
        "from langchain import hub\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "\n",
        "# Load some data to summarize\n",
        "loader = WebBaseLoader(\"https://www.aitimes.com/news/articleView.html?idxno=131777\")\n",
        "docs = loader.load()\n",
        "content = docs[0].page_content\n",
        "\n",
        "\n",
        "class StreamCallback(BaseCallbackHandler):\n",
        "    def on_llm_new_token(self, token, **kwargs):\n",
        "        print(token, end=\"\", flush=True)\n",
        "\n",
        "\n",
        "prompt = hub.pull(\"teddynote/chain-of-density-korean\")\n",
        "\n",
        "# Create the chain, including\n",
        "chain = (\n",
        "    prompt\n",
        "    | ChatGoogleGenerativeAI(\n",
        "        temperature=0,\n",
        "        model=\"gemini-pro\",\n",
        "        streaming=True,\n",
        "        callbacks=[StreamCallback()],\n",
        "    )\n",
        "    | JsonOutputParser()\n",
        "    | (lambda x: x[-1][\"Denser_Summary\"])\n",
        ")\n",
        "\n",
        "# Invoke the chain\n",
        "result = chain.invoke({\"ARTICLE\": content})\n",
        "display(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "1qhSgFzpX5A3",
        "outputId": "e0c8b3d0-bd9c-45e4-c2da-e2521077cd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ëŠ” ë¹…ë°ì´í„° ì‹œëŒ€ ìœµí•© í•™ë¬¸ìœ¼ë¡œì„œ, ê¸°ì¡´ í†µê³„ì  ê¸°ë²•ê³¼ ìµœê·¼ì˜ ë¨¸ì‹ ëŸ¬ë‹ ë° ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì„ í•™ë¬¸ì ìœ¼ë¡œ ì—°êµ¬í•˜ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤. ì‹¤ìš©ì ì¸ ì¸¡ë©´ì—ì„œëŠ” ë°ì´í„°ë¥¼ íšë“í•˜ê³ , ì—¬ê¸°ì— ì „ë¬¸ ì§€ì‹ì„ ì ‘ëª©í•´ ì²˜ë¦¬í•˜ê±°ë‚˜ ëª¨ë¸ë§í™” í•˜ê±°ë‚˜ ì‹œê°í™”í•˜ëŠ” ê³¼ì •ì„ í†µí•´ ìš°ë¦¬ ì‹¤ìƒí™œì— ìœ ìš©í•œ ì†”ë£¨ì…˜ì„ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ë¬¸ì„œ ì „ì²´ ìš”ì•½(Stuff Documents Chain)"
      ],
      "metadata": {
        "id": "bO2XPGz9AZMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "stuff documents chain(\"stuff\"ëŠ” \"ì±„ìš°ë‹¤\" ë˜ëŠ” \"ì±„ìš°ê¸° ìœ„í•´\"ì˜ ì˜ë¯¸)ëŠ” ë¬¸ì„œ ì²´ì¸ ì¤‘ ê°€ì¥ ê°„ë‹¨í•œ ë°©ì‹ì…ë‹ˆë‹¤. ë¬¸ì„œ ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ ëª¨ë‘ í”„ë¡¬í”„íŠ¸ì— ì‚½ì…í•œ ë‹¤ìŒ, ê·¸ í”„ë¡¬í”„íŠ¸ë¥¼ LLMì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ ì²´ì¸ì€ ë¬¸ì„œê°€ ì‘ê³  ëŒ€ë¶€ë¶„ì˜ í˜¸ì¶œì— ëª‡ ê°œë§Œ ì „ë‹¬ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "0sHiAHa7AgJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchainhub langchain_community -q\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert summarizer. Please summarize the following sentence.\",\n",
        "        ),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"Please summarize the sentence according to the following request.\"\n",
        "            \"\\nREQUEST:\\n\"\n",
        "            \"1. Summarize the main points in bullet points in Korean.\"\n",
        "            \"2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\"\n",
        "            \"3. Use various emojis to make the summary more interesting.\"\n",
        "            \"\\n\\nCONTEXT: {context}\\n\\nSUMMARY:\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSEwVCLzAii_",
        "outputId": "39e86bd4-bfae-435a-9535-45072fce6261"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert summarizer. Please summarize the following sentence.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='Please summarize the sentence according to the following request.\\nREQUEST:\\n1. Summarize the main points in bullet points in Korean.2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.3. Use various emojis to make the summary more interesting.\\n\\nCONTEXT: {context}\\n\\nSUMMARY:'))])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTF-HXzRA0Mp",
        "outputId": "faa03125-f3eb-4ea8-c536-7f6126a9ba0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context'], metadata={'lc_hub_owner': 'teddynote', 'lc_hub_repo': 'summary-stuff-documents-korean', 'lc_hub_commit_hash': 'c45b97ed375ce5251c42cfd9638dfecd2eaeb5ff4904838771d2a26ac3e2a5f6'}, template='Please summarize the sentence according to the following REQUEST.\\nREQUEST:\\n1. Summarize the main points in bullet points in KOREAN.\\n2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\\n3. Use various emojis to make the summary more interesting.\\n4. Translate the summary into KOREAN if it is written in ENGLISH.\\n5. DO NOT translate any technical terms.\\n6. DO NOT include any unnecessary information.\\n\\nCONTEXT:\\n{context}\\n\\nSUMMARY:\"\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"data/news.txt\")\n",
        "docs = loader.load()\n",
        "print(f\"ë¬¸ì„œì˜ ìˆ˜: {len(docs)}\\n\")\n",
        "print(\"[ë©”íƒ€ë°ì´í„°]\\n\")\n",
        "print(docs[0].metadata)\n",
        "print(\"\\n========= [ì•ë¶€ë¶„] ë¯¸ë¦¬ë³´ê¸° =========\\n\")\n",
        "print(docs[0].page_content[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "0am6nAUPAqWH",
        "outputId": "5ff17436-d457-4700-9ee1-1028ca22d079"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error loading data/news.txt",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/text.py\u001b[0m in \u001b[0;36mlazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/news.txt'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2dacfd442aae>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/news.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ë¬¸ì„œì˜ ìˆ˜: {len(docs)}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[ë©”íƒ€ë°ì´í„°]\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/document_loaders/base.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;34m\"\"\"Load data into Document objects.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/text.py\u001b[0m in \u001b[0;36mlazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error loading {self.file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error loading {self.file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error loading data/news.txt"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MyCallbackHandler í´ë˜ìŠ¤ëŠ” BaseCallbackHandlerë¥¼ ìƒì†ë°›ì•„, ì–¸ì–´ ëª¨ë¸ì´ ìƒˆë¡œìš´ í† í°ì„ ìƒì„±í•  ë•Œë§ˆë‹¤ í•´ë‹¹ í† í°ì„ ì¶œë ¥í•˜ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "\n",
        "ChatOpenAI ê°ì²´ëŠ” GPT-3.5-turbo ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©°, ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì™€ ë‚®ì€ ì˜¨ë„ ì„¤ì •ì„ í†µí•´ ë” ì¼ê´€ëœ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ êµ¬ì„±ë©ë‹ˆë‹¤. ì´ ê°ì²´ëŠ” ì½œë°±ìœ¼ë¡œ MyCallbackHandler ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ, create_stuff_documents_chain í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ìƒì„± ì²´ì¸ì„ ë§Œë“¤ê³ , ì´ ì²´ì¸ì„ í†µí•´ ì£¼ì–´ì§„ ë¬¸ë§¥(docs)ì— ëŒ€í•œ ì‘ë‹µ(answer)ì„ ìƒì„±í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "FNsfDf4sBDup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "\n",
        "class MyCallbackHandler(BaseCallbackHandler):\n",
        "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
        "        print(f\"{token}\", end=\"\", flush=True)\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    streaming=True,\n",
        "    temperature=0.01,\n",
        "    callbacks=[MyCallbackHandler()],\n",
        ")\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "answer = chain.invoke({\"context\": docs})"
      ],
      "metadata": {
        "id": "bBEUecvLBCKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì›¹ë¬¸ì„œ ìš”ì•½(Webpage Summarization Chain)"
      ],
      "metadata": {
        "id": "sV5ycC05BIno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WMLSRZkBBKUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "\n",
        "# Load some data to summarize\n",
        "loader = WebBaseLoader(\"https://www.aitimes.com/news/articleView.html?idxno=131777\")\n",
        "docs = loader.load()\n",
        "content = docs[0].page_content\n",
        "\n",
        "\n",
        "class StreamCallback(BaseCallbackHandler):\n",
        "    def on_llm_new_token(self, token, **kwargs):\n",
        "        print(token, end=\"\", flush=True)\n",
        "\n",
        "\n",
        "prompt = hub.pull(\"teddynote/chain-of-density-korean\")\n",
        "\n",
        "# Create the chain, including\n",
        "chain = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | JsonOutputParser()\n",
        "    | (lambda x: x[-1][\"Denser_Summary\"])\n",
        ")\n",
        "\n",
        "# Invoke the chain\n",
        "result = chain.invoke({\"ARTICLE\": content})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAqBdIOsBLbk",
        "outputId": "94fb755a-72da-462f-f6f5-e250b48d7cfd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ëŠ” ë¹…ë°ì´í„° ì‹œëŒ€ ìœµí•© í•™ë¬¸ìœ¼ë¡œ, ê¸°ì¡´ í†µê³„ì  ê¸°ë²•ê³¼ ìµœê·¼ì˜ ë¨¸ì‹ ëŸ¬ë‹ ë° ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì„ í•™ë¬¸ì ìœ¼ë¡œ ì—°êµ¬í•˜ëŠ” ë¶„ì•¼ì´ë‹¤. ì‹¤ìš©ì ì¸ ì¸¡ë©´ì—ì„œëŠ” ë°ì´í„°ë¥¼ íšë“í•˜ê³ , ì—¬ê¸°ì— ì „ë¬¸ ì§€ì‹ì„ ì ‘ëª©í•´ ì²˜ë¦¬í•˜ê±°ë‚˜ ëª¨ë¸ë§í™” í•˜ê±°ë‚˜ ì‹œê°í™”í•˜ëŠ” ê³¼ì •ì„ í†µí•´ ìš°ë¦¬ ì‹¤ìƒí™œì— ìœ ìš©í•œ ì†”ë£¨ì…˜ì„ ë§Œë“œëŠ” ê²ƒì´ë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "\n",
        "# Load some data to summarize\n",
        "loader = WebBaseLoader(\"https://lineage2m.plaync.com/guidebook/view?title=%EC%A2%85%EC%A1%B1%20%EC%86%8C%EA%B0%9C\")\n",
        "docs = loader.load()\n",
        "content = docs[0].page_content\n",
        "\n",
        "\n",
        "class StreamCallback(BaseCallbackHandler):\n",
        "    def on_llm_new_token(self, token, **kwargs):\n",
        "        print(token, end=\"\", flush=True)\n",
        "\n",
        "\n",
        "prompt = hub.pull(\"teddynote/chain-of-density-korean\")\n",
        "\n",
        "# Create the chain, including\n",
        "chain = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | JsonOutputParser()\n",
        "    | (lambda x: x[-1][\"Denser_Summary\"])\n",
        ")\n",
        "\n",
        "# Invoke the chain\n",
        "result = chain.invoke({\"ARTICLE\": content})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpNEdMmWBnH6",
        "outputId": "b761670d-ee94-47c1-ed5e-f0c360798b38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NCSOFTì˜ ë¦¬ë‹ˆì§€2M ê°€ì´ë“œë¶ì€ ê²Œì„ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê°€ì´ë“œë¶ì…ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SimpleSequentialChain"
      ],
      "metadata": {
        "id": "ERwZADuVGaHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chains ìì²´ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "SHrYBUWTISYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "\n",
        "# write\n",
        "write_article_chain = LLMChain(llm=llm, prompt=PromptTemplate(template=\"{input}ì— ê´€í•œ ê¸°ì‚¬ë¥¼ ì¨ì£¼ì„¸ìš”\", input_variables=[\"input\"],),)\n",
        "#translate\n",
        "translate_chain = LLMChain(llm=llm, prompt=PromptTemplate(template=\"ë‹¤ìŒ ë¬¸ì¥ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ ì£¼ì„¸ìš”. \\n{input}\", input_variables=[\"input\"],),)\n",
        "#sequential\n",
        "sequential_chain = SimpleSequentialChain(chains=[\n",
        "    write_article_chain,\n",
        "    translate_chain,\n",
        "])\n",
        "\n",
        "result=sequential_chain.run(\"ì¼ë ‰íŠ¸ë¦­ ê¸°íƒ€ ì„ íƒ ë°©ë²•\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIORzGw2GfI6",
        "outputId": "bbfb8a1a-1758-49a9-b5d2-e54832cf589c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**How to Choose an Electric Guitar**\n",
            "\n",
            "Choosing an electric guitar can be an exciting but overwhelming process. With so many different brands, models, and features available, it's important to find the guitar that's the best fit for you. This article will guide you through the key factors to consider when choosing an electric guitar.\n",
            "\n",
            "**1. Set a Budget**\n",
            "\n",
            "Electric guitars range widely in price. Beginner guitars can be purchased for a few hundred dollars, while high-end models can cost thousands. Setting a budget will help you narrow down your choices.\n",
            "\n",
            "**2. Consider Your Purpose**\n",
            "\n",
            "Think about what you'll be using the guitar for. Will you be playing a specific genre, such as rock, blues, or jazz, or will you be playing a variety of styles? Different genres require different tones and playability.\n",
            "\n",
            "**3. Choose a Body Style**\n",
            "\n",
            "Electric guitars come in a variety of body styles. The most common styles include:\n",
            "\n",
            "* **Solid Body:** Made from a solid block of wood, providing sustain and a clear tone.\n",
            "* **Semi-Hollow Body:** A hybrid design with a solid body and resonant chambers, offering a warm and rich tone.\n",
            "* **Hollow Body:** A fully hollow body with resonant chambers, ideal for jazz and blues.\n",
            "\n",
            "**4. Consider Pickups**\n",
            "\n",
            "Pickups are magnets that convert the vibrations in the guitar into an electrical signal. Different pickup types produce different tones.\n",
            "\n",
            "* **Single-Coil:** Provide a bright, clean tone.\n",
            "* **Humbucker:** Provide a warm, rich tone, also known as a double-coil.\n",
            "* **P-90:** Combine characteristics of single-coils and humbuckers, offering a vintage tone.\n",
            "\n",
            "**5. Choose a Wood**\n",
            "\n",
            "The wood of the guitar affects its tone and playability. Common woods used include:\n",
            "\n",
            "* **Mahogany:** Provides a warm, rich tone.\n",
            "* **Maple:** Provides a bright, clear tone.\n",
            "* **Rosewood:** Provides a warm, round tone.\n",
            "\n",
            "**6. Select a Fretboard Material**\n",
            "\n",
            "The fretboard is the piece of wood that you play on. Common materials used include:\n",
            "\n",
            "* **Rosewood:** Provides a warm, smooth feel.\n",
            "* **Maple:** Provides a bright, snappy feel.\n",
            "* **Ebony:** Hard and durable, providing a clear tone.\n",
            "\n",
            "**7. Scale Length**\n",
            "\n",
            "The scale length is the distance from the nut to the bridge. Guitars with longer scale lengths generally have a lower pitch and more sustain.\n",
            "\n",
            "**8. Hardware**\n",
            "\n",
            "Hardware refers to components of the guitar such as the bridge, tuners, and jack. High-quality hardware improves tuning stability, intonation, and durability.\n",
            "\n",
            "**9. Consider Amp and Pedals**\n",
            "\n",
            "Guitars are used in conjunction with amplifiers and pedals to create the desired tone. Consider the compatibility of the guitar with your amp and pedals when making your choice.\n",
            "\n",
            "**10. Test Drive**\n",
            "\n",
            "If possible, test drive the guitar before you buy it. Play different guitars and see which one feels the most comfortable and inspires you.\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "Choosing an electric guitar is a personal decision based on your preferences and needs. By considering the factors outlined in this article, you can find the guitar that's the best fit for you. Take your time, do your research, and test drive different guitars to find the perfect instrument.\n"
          ]
        }
      ]
    }
  ]
}